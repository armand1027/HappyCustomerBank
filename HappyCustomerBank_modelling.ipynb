{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, roc_curve, confusion_matrix, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from tabulate import tabulate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86546, 36)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Loan_Amount_Applied</th>\n",
       "      <th>Loan_Tenure_Applied</th>\n",
       "      <th>Existing_EMI</th>\n",
       "      <th>Mobile_Verified</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Loan_Amount_Submitted</th>\n",
       "      <th>Loan_Tenure_Submitted</th>\n",
       "      <th>Interest_Rate</th>\n",
       "      <th>Processing_Fee</th>\n",
       "      <th>...</th>\n",
       "      <th>Var1_cat_II</th>\n",
       "      <th>Var1_cat_III</th>\n",
       "      <th>Var2_cat_I</th>\n",
       "      <th>Var2_cat_II</th>\n",
       "      <th>Var4_cat_I</th>\n",
       "      <th>Var4_cat_II</th>\n",
       "      <th>Var4_cat_III</th>\n",
       "      <th>Source_cat_I</th>\n",
       "      <th>Source_cat_II</th>\n",
       "      <th>Source_cat_III</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86541</th>\n",
       "      <td>87015</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86542</th>\n",
       "      <td>87016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35.50</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86543</th>\n",
       "      <td>87017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86544</th>\n",
       "      <td>87018</td>\n",
       "      <td>800000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13660.0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86545</th>\n",
       "      <td>87019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.99</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86546 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Loan_Amount_Applied  Loan_Tenure_Applied  Existing_EMI  \\\n",
       "0               0             300000.0                  5.0           0.0   \n",
       "1               1             200000.0                  2.0           0.0   \n",
       "2               2             600000.0                  4.0           0.0   \n",
       "3               3            1000000.0                  5.0           0.0   \n",
       "4               4             500000.0                  2.0       25000.0   \n",
       "...           ...                  ...                  ...           ...   \n",
       "86541       87015            1000000.0                  5.0       14500.0   \n",
       "86542       87016                  0.0                  0.0           0.0   \n",
       "86543       87017                  0.0                  0.0           0.0   \n",
       "86544       87018             800000.0                  5.0       13660.0   \n",
       "86545       87019                  0.0                  0.0           0.0   \n",
       "\n",
       "       Mobile_Verified  Var5  Loan_Amount_Submitted  Loan_Tenure_Submitted  \\\n",
       "0                    0     0                    5.0                    0.0   \n",
       "1                    1    13                    2.0                    2.0   \n",
       "2                    1     0                    4.0                    4.0   \n",
       "3                    1    10                    5.0                    5.0   \n",
       "4                    1    17                    2.0                    2.0   \n",
       "...                ...   ...                    ...                    ...   \n",
       "86541                0     9                    5.0                    0.0   \n",
       "86542                1     1                    0.0                    4.0   \n",
       "86543                1     8                    0.0                    4.0   \n",
       "86544                1    18                    5.0                    5.0   \n",
       "86545                1    12                    0.0                    4.0   \n",
       "\n",
       "       Interest_Rate  Processing_Fee  ...  Var1_cat_II  Var1_cat_III  \\\n",
       "0               0.00             0.0  ...            0             1   \n",
       "1              13.25             0.0  ...            0             0   \n",
       "2               0.00             0.0  ...            0             1   \n",
       "3               0.00             0.0  ...            0             1   \n",
       "4               0.00             0.0  ...            0             1   \n",
       "...              ...             ...  ...          ...           ...   \n",
       "86541           0.00             0.0  ...            0             1   \n",
       "86542          35.50          4800.0  ...            0             1   \n",
       "86543           0.00             0.0  ...            0             1   \n",
       "86544           0.00             0.0  ...            0             1   \n",
       "86545          13.99          3450.0  ...            0             0   \n",
       "\n",
       "       Var2_cat_I  Var2_cat_II  Var4_cat_I  Var4_cat_II  Var4_cat_III  \\\n",
       "0               0            1           0            0             1   \n",
       "1               0            1           0            1             0   \n",
       "2               1            0           0            0             1   \n",
       "3               1            0           0            1             0   \n",
       "4               1            0           0            1             0   \n",
       "...           ...          ...         ...          ...           ...   \n",
       "86541           0            1           0            1             0   \n",
       "86542           0            1           1            0             0   \n",
       "86543           0            1           0            1             0   \n",
       "86544           0            1           0            1             0   \n",
       "86545           0            1           0            1             0   \n",
       "\n",
       "       Source_cat_I  Source_cat_II  Source_cat_III  \n",
       "0                 0              1               0  \n",
       "1                 0              1               0  \n",
       "2                 0              1               0  \n",
       "3                 0              1               0  \n",
       "4                 0              1               0  \n",
       "...             ...            ...             ...  \n",
       "86541             0              1               0  \n",
       "86542             0              1               0  \n",
       "86543             0              1               0  \n",
       "86544             0              1               0  \n",
       "86545             0              1               0  \n",
       "\n",
       "[86546 rows x 36 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Data/data_processed.csv')\n",
    "print(data.shape)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 86546 entries, 0 to 86545\n",
      "Data columns (total 35 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Loan_Amount_Applied    86546 non-null  float64\n",
      " 1   Loan_Tenure_Applied    86546 non-null  float64\n",
      " 2   Existing_EMI           86546 non-null  float64\n",
      " 3   Mobile_Verified        86546 non-null  int64  \n",
      " 4   Var5                   86546 non-null  int64  \n",
      " 5   Loan_Amount_Submitted  86546 non-null  float64\n",
      " 6   Loan_Tenure_Submitted  86546 non-null  float64\n",
      " 7   Interest_Rate          86546 non-null  float64\n",
      " 8   Processing_Fee         86546 non-null  float64\n",
      " 9   EMI_Loan_Submitted     86546 non-null  float64\n",
      " 10  Filled_Form            86546 non-null  int64  \n",
      " 11  Disbursed              86546 non-null  int64  \n",
      " 12  Cty_cat_I              86546 non-null  int64  \n",
      " 13  Cty_cat_II             86546 non-null  int64  \n",
      " 14  Cty_cat_III            86546 non-null  int64  \n",
      " 15  Cty_cat_IV             86546 non-null  int64  \n",
      " 16  Cty_cat_V              86546 non-null  int64  \n",
      " 17  Age                    86546 non-null  int64  \n",
      " 18  Mntly_Incm_log         86546 non-null  float64\n",
      " 19  Employer_cat           86546 non-null  int64  \n",
      " 20  Male                   86546 non-null  int64  \n",
      " 21  Wb_brwsr               86546 non-null  int64  \n",
      " 22  Missing_LAA            86546 non-null  int64  \n",
      " 23  Missing_LTA            86546 non-null  int64  \n",
      " 24  Var1_cat_I             86546 non-null  int64  \n",
      " 25  Var1_cat_II            86546 non-null  int64  \n",
      " 26  Var1_cat_III           86546 non-null  int64  \n",
      " 27  Var2_cat_I             86546 non-null  int64  \n",
      " 28  Var2_cat_II            86546 non-null  int64  \n",
      " 29  Var4_cat_I             86546 non-null  int64  \n",
      " 30  Var4_cat_II            86546 non-null  int64  \n",
      " 31  Var4_cat_III           86546 non-null  int64  \n",
      " 32  Source_cat_I           86546 non-null  int64  \n",
      " 33  Source_cat_II          86546 non-null  int64  \n",
      " 34  Source_cat_III         86546 non-null  int64  \n",
      "dtypes: float64(9), int64(26)\n",
      "memory usage: 23.1 MB\n"
     ]
    }
   ],
   "source": [
    "del data['Unnamed: 0']\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divides the sample into a test and training part. Due to the unbalanced classes, I use the 'stratify' attribute so that the distribution of Y for the two samples are similar. \n",
    "Proportion - Disbursed: 0 to Disbursed: 1 is 67/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (86546, 34) y.shape: (86546,)\n"
     ]
    }
   ],
   "source": [
    "y = data['Disbursed'].astype(\"category\")\n",
    "X = data.drop('Disbursed',axis=1)\n",
    "print(\"X.shape: {} y.shape: {}\".format(X.shape, y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the feature_names later in the zip function. It will be used to pair with the list. The list of columns will be compared and assigned to the list from BorutaPy, which will identify the appropriate columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Loan_Amount_Applied', 'Loan_Tenure_Applied', 'Existing_EMI',\n",
       "       'Mobile_Verified', 'Var5', 'Loan_Amount_Submitted',\n",
       "       'Loan_Tenure_Submitted', 'Interest_Rate', 'Processing_Fee',\n",
       "       'EMI_Loan_Submitted', 'Filled_Form', 'Cty_cat_I', 'Cty_cat_II',\n",
       "       'Cty_cat_III', 'Cty_cat_IV', 'Cty_cat_V', 'Age', 'Mntly_Incm_log',\n",
       "       'Employer_cat', 'Male', 'Wb_brwsr', 'Missing_LAA', 'Missing_LTA',\n",
       "       'Var1_cat_I', 'Var1_cat_II', 'Var1_cat_III', 'Var2_cat_I',\n",
       "       'Var2_cat_II', 'Var4_cat_I', 'Var4_cat_II', 'Var4_cat_III',\n",
       "       'Source_cat_I', 'Source_cat_II', 'Source_cat_III'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = np.array(X.columns)\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data standardize using Standard Scaler to transform data columns values to certain ranges.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divides the sample into a test and training part. Due to the unbalanced classes, I use the 'stratify' attribute so that the distribution of the expense variable for the two samples are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=data[\"Disbursed\"],\n",
    "                                                    test_size=0.2, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train.value_counts: \n",
      "0    68219\n",
      "1     1017\n",
      "Name: Disbursed, dtype: int64 \n",
      "y_test.value_counts: \n",
      "0    17056\n",
      "1      254\n",
      "Name: Disbursed, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"y_train.value_counts: \\n{} \\ny_test.value_counts: \\n{}\".format(y_train.value_counts(), y_test.value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing nonsignificant variables using BorutaPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boruta is an all-relevant feature selection method. It tries to capture all the important, interesting features you might have in your dataset with respect to an outcome variable. Classifier will be trained on our dataset, such that we get importances for each of our features. Tree ensemble methods such as Random Forest can capture non-linear highly intricate relationships between our predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1, class_weight={0: 1, 1: 10}, max_depth=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from boruta import BorutaPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_selector = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=48, max_iter=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 15\n",
      "Confirmed: \t0\n",
      "Tentative: \t34\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 15\n",
      "Confirmed: \t0\n",
      "Tentative: \t34\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 15\n",
      "Confirmed: \t0\n",
      "Tentative: \t34\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 15\n",
      "Confirmed: \t0\n",
      "Tentative: \t34\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 15\n",
      "Confirmed: \t0\n",
      "Tentative: \t34\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 15\n",
      "Confirmed: \t0\n",
      "Tentative: \t34\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 15\n",
      "Confirmed: \t0\n",
      "Tentative: \t34\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 15\n",
      "Confirmed: \t11\n",
      "Tentative: \t6\n",
      "Rejected: \t17\n",
      "Iteration: \t9 / 15\n",
      "Confirmed: \t11\n",
      "Tentative: \t6\n",
      "Rejected: \t17\n",
      "Iteration: \t10 / 15\n",
      "Confirmed: \t11\n",
      "Tentative: \t6\n",
      "Rejected: \t17\n",
      "Iteration: \t11 / 15\n",
      "Confirmed: \t11\n",
      "Tentative: \t6\n",
      "Rejected: \t17\n",
      "Iteration: \t12 / 15\n",
      "Confirmed: \t11\n",
      "Tentative: \t3\n",
      "Rejected: \t20\n",
      "Iteration: \t13 / 15\n",
      "Confirmed: \t11\n",
      "Tentative: \t3\n",
      "Rejected: \t20\n",
      "Iteration: \t14 / 15\n",
      "Confirmed: \t11\n",
      "Tentative: \t3\n",
      "Rejected: \t20\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t15 / 15\n",
      "Confirmed: \t11\n",
      "Tentative: \t1\n",
      "Rejected: \t20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BorutaPy(estimator=RandomForestClassifier(class_weight={0: 1, 1: 10},\n",
       "                                          max_depth=6, n_estimators=88,\n",
       "                                          n_jobs=-1,\n",
       "                                          random_state=RandomState(MT19937) at 0x223801FA340),\n",
       "         max_iter=15, n_estimators='auto',\n",
       "         random_state=RandomState(MT19937) at 0x223801FA340, verbose=2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: Loan_Amount_Applied       Rank: 1   , Keep: True\n",
      "Feature: Loan_Tenure_Applied       Rank: 3   , Keep: False\n",
      "Feature: Existing_EMI              Rank: 1   , Keep: True\n",
      "Feature: Mobile_Verified           Rank: 8   , Keep: False\n",
      "Feature: Var5                      Rank: 1   , Keep: True\n",
      "Feature: Loan_Amount_Submitted     Rank: 4   , Keep: False\n",
      "Feature: Loan_Tenure_Submitted     Rank: 1   , Keep: True\n",
      "Feature: Interest_Rate             Rank: 1   , Keep: True\n",
      "Feature: Processing_Fee            Rank: 2   , Keep: False\n",
      "Feature: EMI_Loan_Submitted        Rank: 1   , Keep: True\n",
      "Feature: Filled_Form               Rank: 8   , Keep: False\n",
      "Feature: Cty_cat_I                 Rank: 20  , Keep: False\n",
      "Feature: Cty_cat_II                Rank: 16  , Keep: False\n",
      "Feature: Cty_cat_III               Rank: 22  , Keep: False\n",
      "Feature: Cty_cat_IV                Rank: 21  , Keep: False\n",
      "Feature: Cty_cat_V                 Rank: 14  , Keep: False\n",
      "Feature: Age                       Rank: 1   , Keep: True\n",
      "Feature: Mntly_Incm_log            Rank: 1   , Keep: True\n",
      "Feature: Employer_cat              Rank: 17  , Keep: False\n",
      "Feature: Male                      Rank: 5   , Keep: False\n",
      "Feature: Wb_brwsr                  Rank: 16  , Keep: False\n",
      "Feature: Missing_LAA               Rank: 11  , Keep: False\n",
      "Feature: Missing_LTA               Rank: 10  , Keep: False\n",
      "Feature: Var1_cat_I                Rank: 1   , Keep: True\n",
      "Feature: Var1_cat_II               Rank: 12  , Keep: False\n",
      "Feature: Var1_cat_III              Rank: 1   , Keep: True\n",
      "Feature: Var2_cat_I                Rank: 18  , Keep: False\n",
      "Feature: Var2_cat_II               Rank: 19  , Keep: False\n",
      "Feature: Var4_cat_I                Rank: 3   , Keep: False\n",
      "Feature: Var4_cat_II               Rank: 9   , Keep: False\n",
      "Feature: Var4_cat_III              Rank: 6   , Keep: False\n",
      "Feature: Source_cat_I              Rank: 23  , Keep: False\n",
      "Feature: Source_cat_II             Rank: 1   , Keep: True\n",
      "Feature: Source_cat_III            Rank: 14  , Keep: False\n"
     ]
    }
   ],
   "source": [
    "X_filtered = feat_selector.transform(X_train)\n",
    "feature_ranks = list(zip(feature_names, feat_selector.ranking_, feat_selector.support_))\n",
    "\n",
    "for feat in feature_ranks:\n",
    "    print('Feature: {:<25} Rank: {:<4}, Keep: {}'.format(feat[0], feat[1], feat[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69236, 11)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use DecisionTreeClassifier to evaluate the importance of the features (feature_importances_) in a importance classification task and compare it to the RandomForestClassifier results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9696129404968227"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)\n",
    "dtc.feature_importances_[dtc.feature_importances_>0.017]\n",
    "accuracy_score(y_test, dtc.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.bar(feature_names, dtc.feature_importances_)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, tree collection methods such as Random Forest and Decision Tree Classifier yield similar results on validity. I decide to stick to the columns previously selected with BorutaPy (X_filtered)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below is a definition of a function that will draw a confusion matrix in a simple form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_conf(a):\n",
    "    a_list=a.tolist()\n",
    "    a_list[0].insert(0,'Real 0')\n",
    "    a_list[1].insert(0,'Real 1')\n",
    "    print (tabulate (a_list,headers=['Real/Pred','Pred 0', 'Pred 1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree, Random Forest, Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          68219         0\n",
      "Real 1             44       973\n",
      "F1: 0.9778894472361809\n",
      "AUC:  0.9999858097705258\n"
     ]
    }
   ],
   "source": [
    "model_1 = DecisionTreeClassifier()\n",
    "model_1.fit(X_filtered, y_train)\n",
    "y_pred = model_1.predict_proba(X_filtered)[:,1]\n",
    "predictions = np.where(y_pred>0.5,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          68219         0\n",
      "Real 1             47       970\n",
      "F1: 0.9763462506290891\n",
      "AUC:  0.9999779975771534\n"
     ]
    }
   ],
   "source": [
    "model_2 = RandomForestClassifier()\n",
    "model_2.fit(X_filtered, y_train)\n",
    "y_pred = model_2.predict_proba(X_filtered)[:,1]\n",
    "predictions = np.where(y_pred>0.5,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          68212         7\n",
      "Real 1           1016         1\n",
      "F1: 0.001951219512195122\n",
      "AUC:  0.8099223950835763\n"
     ]
    }
   ],
   "source": [
    "model_3 = LogisticRegression()\n",
    "model_3.fit(X_filtered, y_train)\n",
    "y_pred = model_3.predict_proba(X_filtered)[:,1]\n",
    "predictions = np.where(y_pred>0.5,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters for the above models were adjusted by testing. \n",
    "### Below we will apply grid searching to find the best parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are symptoms of overfitting in tree models. To fix this, we will add a constraint like min_samples_leaf for this particular model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate of DecisionTreeClassifier: 0.963280 using {'ccp_alpha': 0.0, 'class_weight': 'balanced', 'criterion': 'entropy', 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# grid searching key hyperparametres for logistic regression\n",
    "\n",
    "# define models and parameters\n",
    "dt_model = DecisionTreeClassifier(min_samples_leaf=2)\n",
    "criterion = [\"gini\", \"entropy\"]\n",
    "splitter = [\"best\", \"random\"]\n",
    "class_weight = [\"{0: 2, 1: 1}\",\"{0: 1, 1: 2}\",\"balanced\"]\n",
    "ccp_alpha = [0.0, 0.01, 0.1]\n",
    "# define grid search\n",
    "grid = dict(criterion=criterion,splitter=splitter,class_weight=class_weight,ccp_alpha=ccp_alpha)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=dt_model, param_grid=grid, n_jobs=-1, cv=cv, \n",
    "                           scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_filtered, y_train)\n",
    "# summarize results\n",
    "print(\"Accuracy rate of DecisionTreeClassifier: %f using %s\" % (grid_result.best_score_, \n",
    "                                                                grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          67581       638\n",
      "Real 1              0      1017\n",
      "F1: 0.7612275449101796\n",
      "AUC:  0.9978975398552666\n"
     ]
    }
   ],
   "source": [
    "model_1 = DecisionTreeClassifier(ccp_alpha=0.0, class_weight='balanced', criterion='entropy', \n",
    "                                 min_samples_leaf=2, splitter='best')\n",
    "model_1.fit(X_filtered, y_train)\n",
    "y_pred = model_1.predict_proba(X_filtered)[:,1]\n",
    "predictions = np.where(y_pred>0.5,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate of RandomForestClassifier: 0.985253 using {'class_weight': {0: 1, 1: 2}, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "# define models and parameters\n",
    "rf_model = RandomForestClassifier(min_samples_leaf=2)\n",
    "n_estimators = [50, 200]\n",
    "class_weight = [ \"balanced\", {0: 1, 1: 2}, {0: 1, 1: 3}]\n",
    "# define grid search\n",
    "grid = dict(n_estimators=n_estimators,class_weight=class_weight)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=grid, n_jobs=-1, cv=cv, \n",
    "                           scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_filtered, y_train)\n",
    "# summarize results\n",
    "print(\"Accuracy rate of RandomForestClassifier: %f using %s\" % (grid_result.best_score_, \n",
    "                                                                grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          68218         1\n",
      "Real 1            797       220\n",
      "F1: 0.35541195476575116\n",
      "AUC:  0.9997280794574441\n"
     ]
    }
   ],
   "source": [
    "model_2 = RandomForestClassifier(n_estimators=50, class_weight={0: 1, 1: 2}, criterion = \"gini\", \n",
    "                                 min_samples_leaf=2)\n",
    "model_2.fit(X_filtered, y_train)\n",
    "y_pred = model_2.predict_proba(X_filtered)[:,1]\n",
    "predictions = np.where(y_pred>0.5,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate of Logistic Regression: 0.985311 using {'C': 0.0001, 'class_weight': '{0: 1, 1: 10}', 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "# define models and parameters\n",
    "lr_model = LogisticRegression(max_iter=300)\n",
    "solvers = ['liblinear', 'lbfgs','newton-cg']\n",
    "penalty=['l2', 'l1']\n",
    "class_weight = [\"{0: 1, 1: 10}\",\"{0: 2, 1: 1}\",\"{0: 1, 1: 2}\",\"balanced\"]\n",
    "c_values = [0.01, 0.001, 0.0001]\n",
    "# define grid search\n",
    "grid = dict(solver=solvers,penalty=penalty,C=c_values,class_weight=class_weight)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=lr_model, param_grid=grid, n_jobs=-1, cv=cv, \n",
    "                           scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_filtered, y_train)\n",
    "# summarize results\n",
    "print(\"Accuracy rate of Logistic Regression: %f using %s\" % (grid_result.best_score_, \n",
    "                                                             grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          68059       160\n",
      "Real 1            998        19\n",
      "F1: 0.03177257525083612\n",
      "AUC:  0.8117596442355965\n"
     ]
    }
   ],
   "source": [
    "model_3 = LogisticRegression(C=0.0001, class_weight={0: 1, 1: 10}, penalty='l2', solver='lbfgs', \n",
    "                             max_iter=300, n_jobs=12)\n",
    "model_3.fit(X_filtered, y_train)\n",
    "y_pred = model_3.predict_proba(X_filtered)[:,1]\n",
    "predictions = np.where(y_pred>0.5,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:50:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy rate of Logistic Regression: 0.985075 using {'num_parallel_tree': 10}\n"
     ]
    }
   ],
   "source": [
    "# define models and parameters\n",
    "xgb_model = XGBClassifier(use_label_encoder=False)\n",
    "num_parallel_tree = [10, 40]\n",
    "# define grid search\n",
    "grid = dict(num_parallel_tree=num_parallel_tree)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=grid, n_jobs=-1, cv=cv, \n",
    "                           scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_filtered, y_train)\n",
    "# summarize results\n",
    "print(\"Accuracy rate of Logistic Regression: %f using %s\" % (grid_result.best_score_, \n",
    "                                                             grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:50:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          68219         0\n",
      "Real 1            924        93\n",
      "F1: 0.16756756756756755\n",
      "AUC:  0.9616529912203775\n"
     ]
    }
   ],
   "source": [
    "model_4 = XGBClassifier(use_label_encoder=False, n_estimators=100, num_parallel_tree=10)       \n",
    "model_4.fit(X_filtered, y_train)\n",
    "y_pred = model_4.predict_proba(X_filtered)[:,1]\n",
    "predictions = np.where(y_pred>0.5,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final establishing the best cut off threshold in terms of F1 score while using best params in a for loop. The best model will be one with the best F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7598, 0.7598, 0.7598, 0.7598, 0.7598, 0.7598, 0.7598, 0.7598, 0.7598, 0.7622]\n",
      "DecisionTreeClassifier Best F1: 0.7622 threshold: 0.9\n",
      "[0.056, 0.5256, 0.8793, 0.9483, 0.7505, 0.353, 0.0847, 0.0078, 0.0, 0.0]\n",
      "RandomForestClassifier Best F1: 0.9483 threshold: 0.30000000000000004\n",
      "[0.029, 0.0597, 0.0931, 0.115, 0.0788, 0.0318, 0.0183, 0.0057, 0.0039, 0.002]\n",
      "LogisticRegression Best F1: 0.115 threshold: 0.30000000000000004\n",
      "[13:50:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0.029, 0.4768, 0.5033, 0.3824, 0.2596, 0.1676, 0.0973, 0.0517, 0.0098, 0.0]\n",
      "XGBClassifier Best F1: 0.5033 threshold: 0.2\n"
     ]
    }
   ],
   "source": [
    "models_Params_Tresholds = [DecisionTreeClassifier(ccp_alpha=0.0, class_weight='balanced', \n",
    "                                                  criterion='entropy', min_samples_leaf=2, \n",
    "                                                  splitter='best'),\n",
    "                           RandomForestClassifier(n_estimators=50, class_weight={0: 1, 1: 2}, \n",
    "                                                  criterion = \"gini\", min_samples_leaf=2),\n",
    "                           LogisticRegression(C=0.0001, class_weight={0: 1, 1: 10}, penalty='l2', \n",
    "                                              solver='lbfgs', max_iter=300,n_jobs=12),\n",
    "                           XGBClassifier(use_label_encoder=False, n_estimators=100, num_parallel_tree=10)]\n",
    "m = ['DecisionTreeClassifier','RandomForestClassifier','LogisticRegression', 'XGBClassifier']\n",
    "i = 0\n",
    "for model in models_Params_Tresholds:    \n",
    "    model.fit(X_filtered, y_train)\n",
    "    y_pred = model.predict_proba(X_filtered)[:,1]\n",
    "    r = []\n",
    "    for x in np.arange(0,1,0.1):\n",
    "        z = np.where(y_pred > x,1,0)\n",
    "        f = f1_score(y_train, z)\n",
    "        r.append(round(f,4))\n",
    "    print(r)    \n",
    "    print(m[i], \"Best F1:\", np.max(r),\"threshold:\" ,np.argmax(r)*0.1)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will search more broadly around the value of 0.3 threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8846, 0.8979, 0.9108, 0.9199, 0.9298, 0.9368, 0.9453, 0.9476, 0.95, 0.9482, 0.9464, 0.9412, 0.9337, 0.9195, 0.9021, 0.8848, 0.8648, 0.8492, 0.8211, 0.7908]\n",
      "RandomForestClassifier  Best F1: 0.95 threshold: 0.28\n"
     ]
    }
   ],
   "source": [
    "models_Params_Tresholds = [RandomForestClassifier(n_estimators=50, class_weight={0: 1, 1: 2}, \n",
    "                                                  criterion = \"gini\", min_samples_leaf=2)]\n",
    "\n",
    "for model in models_Params_Tresholds:    \n",
    "    model.fit(X_filtered, y_train)\n",
    "    y_pred = model.predict_proba(X_filtered)[:,1]\n",
    "    r = []\n",
    "    for x in np.arange(0.2,0.4,0.01):\n",
    "        z = np.where(y_pred > x,1,0)\n",
    "        f = f1_score(y_train, z)\n",
    "        r.append(round(f,4))\n",
    "    print(r)    \n",
    "    print('RandomForestClassifier ', \"Best F1:\", np.max(r),\"threshold:\" ,np.argmax(r)*0.01+0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          67584       635\n",
      "Real 1              1      1016\n",
      "F1: 0.7616191904047976\n",
      "AUC:  0.9978760202893905\n"
     ]
    }
   ],
   "source": [
    "print('DecisionTreeClassifier')\n",
    "threshold = 0.9\n",
    "\n",
    "model_1 = DecisionTreeClassifier(ccp_alpha=0.0, class_weight='balanced', criterion='entropy', \n",
    "                                 min_samples_leaf=2, splitter='best')\n",
    "model_1.fit(X_filtered, y_train)\n",
    "y_pred = model_1.predict_proba(X_filtered)[:,1]\n",
    "predictions = np.where(y_pred>threshold,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          68135        84\n",
      "Real 1             27       990\n",
      "F1: 0.9469153515064562\n",
      "AUC:  0.9997593426445743\n"
     ]
    }
   ],
   "source": [
    "print('RandomForestClassifier')\n",
    "threshold = 0.28\n",
    "\n",
    "model_2 = RandomForestClassifier(n_estimators=50, class_weight={0: 1, 1: 2},criterion = \"gini\",\n",
    "                                 min_samples_leaf=2)\n",
    "model_2.fit(X_filtered, y_train)\n",
    "y_pred = model_2.predict_proba(X_filtered)[:,1]\n",
    "predictions = np.where(y_pred>threshold,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          65399      2820\n",
      "Real 1            783       234\n",
      "F1: 0.11495946941783344\n",
      "AUC:  0.8117596442355965\n"
     ]
    }
   ],
   "source": [
    "print('LogisticRegression')\n",
    "threshold = 0.3\n",
    "\n",
    "model_3 = LogisticRegression(C=0.0001, class_weight={0: 1, 1: 10}, penalty='l2', solver='lbfgs',\n",
    "                                              max_iter=300,n_jobs=12)\n",
    "model_3.fit(X_filtered, y_train)\n",
    "y_pred = model_3.predict_proba(X_filtered)[:,1]\n",
    "predictions = np.where(y_pred>threshold,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "[13:54:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          68112       107\n",
      "Real 1            639       378\n",
      "F1: 0.5033288948069241\n",
      "AUC:  0.9616529912203775\n"
     ]
    }
   ],
   "source": [
    "print('XGBClassifier')\n",
    "threshold = 0.2\n",
    "\n",
    "model_4 = XGBClassifier(use_label_encoder=False, n_estimators=100, num_parallel_tree=10)\n",
    "model_4.fit(X_filtered, y_train)\n",
    "y_pred = model_4.predict_proba(X_filtered)[:,1]\n",
    "predictions = np.where(y_pred>threshold,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          16678       378\n",
      "Real 1            239        15\n",
      "F1: 0.0463678516228748\n",
      "AUC:  0.5183839755285045\n"
     ]
    }
   ],
   "source": [
    "print('DecisionTreeClassifier')\n",
    "threshold = 0.9\n",
    "\n",
    "model_1 = DecisionTreeClassifier(ccp_alpha=0.0, class_weight='balanced', criterion='entropy', \n",
    "                                 min_samples_leaf=2, splitter='best')\n",
    "model_1.fit(X_train, y_train)\n",
    "y_pred = model_1.predict_proba(X_test)[:,1]\n",
    "predictions = np.where(y_pred>threshold,1,0)\n",
    "print_conf(confusion_matrix(y_test, predictions))\n",
    "print(\"F1:\",f1_score(y_test, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          16897       159\n",
      "Real 1            235        19\n",
      "F1: 0.08796296296296297\n",
      "AUC:  0.7792466409862464\n"
     ]
    }
   ],
   "source": [
    "print('RandomForestClassifier')\n",
    "threshold = 0.2\n",
    "\n",
    "model_2 = RandomForestClassifier(n_estimators=50, class_weight={0: 1, 1: 2},criterion = \"gini\",\n",
    "                                 min_samples_leaf=2)\n",
    "model_2.fit(X_train, y_train)\n",
    "y_pred = model_2.predict_proba(X_test)[:,1]\n",
    "predictions = np.where(y_pred>threshold,1,0)\n",
    "print_conf(confusion_matrix(y_test, predictions))\n",
    "print(\"F1:\",f1_score(y_test, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          16274       782\n",
      "Real 1            198        56\n",
      "F1: 0.10256410256410256\n",
      "AUC:  0.8016103276284883\n"
     ]
    }
   ],
   "source": [
    "print('LogisticRegression')\n",
    "threshold = 0.3\n",
    "\n",
    "model_3 = LogisticRegression(C=0.0001, class_weight={0: 1, 1: 10}, penalty='l2', solver='lbfgs',\n",
    "                                              max_iter=300,n_jobs=12)\n",
    "model_3.fit(X_train, y_train)\n",
    "y_pred = model_3.predict_proba(X_test)[:,1]\n",
    "predictions = np.where(y_pred>threshold,1,0)\n",
    "print_conf(confusion_matrix(y_test, predictions))\n",
    "print(\"F1:\",f1_score(y_test, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "[13:57:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          16969        87\n",
      "Real 1            245         9\n",
      "F1: 0.051428571428571435\n",
      "AUC:  0.8210503427338938\n"
     ]
    }
   ],
   "source": [
    "print('XGBClassifier')\n",
    "threshold = 0.2\n",
    "\n",
    "model_4 = XGBClassifier(use_label_encoder=False, n_estimators=100, num_parallel_tree=10)\n",
    "model_4.fit(X_train, y_train)\n",
    "y_pred = model_4.predict_proba(X_test)[:,1]\n",
    "predictions = np.where(y_pred>threshold,1,0)\n",
    "print_conf(confusion_matrix(y_test, predictions))\n",
    "print(\"F1:\",f1_score(y_test, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, RandomForestClassifier gives us the best F1 score and the best true positive coefficient with an acceptable error rate. The data was prepared using tree methods. The model was well received with a large number of categorical values dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestClassifier(n_estimators=50, class_weight={0: 1, 1: 2},criterion = \"gini\",\n",
    "                                 min_samples_leaf=2)\n",
    "\n",
    "treshold = 0.2\n",
    "\n",
    "F1: 0.088\n",
    "\n",
    "AUC:  0.78"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

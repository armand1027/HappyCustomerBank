{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, roc_curve, confusion_matrix, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from tabulate import tabulate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86546, 36)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Loan_Amount_Applied</th>\n",
       "      <th>Loan_Tenure_Applied</th>\n",
       "      <th>Existing_EMI</th>\n",
       "      <th>Mobile_Verified</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Loan_Amount_Submitted</th>\n",
       "      <th>Loan_Tenure_Submitted</th>\n",
       "      <th>Interest_Rate</th>\n",
       "      <th>Processing_Fee</th>\n",
       "      <th>...</th>\n",
       "      <th>Var1_cat_II</th>\n",
       "      <th>Var1_cat_III</th>\n",
       "      <th>Var2_cat_I</th>\n",
       "      <th>Var2_cat_II</th>\n",
       "      <th>Var4_cat_I</th>\n",
       "      <th>Var4_cat_II</th>\n",
       "      <th>Var4_cat_III</th>\n",
       "      <th>Source_cat_I</th>\n",
       "      <th>Source_cat_II</th>\n",
       "      <th>Source_cat_III</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86541</th>\n",
       "      <td>87015</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86542</th>\n",
       "      <td>87016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35.50</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86543</th>\n",
       "      <td>87017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86544</th>\n",
       "      <td>87018</td>\n",
       "      <td>800000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13660.0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86545</th>\n",
       "      <td>87019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.99</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86546 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Loan_Amount_Applied  Loan_Tenure_Applied  Existing_EMI  \\\n",
       "0               0             300000.0                  5.0           0.0   \n",
       "1               1             200000.0                  2.0           0.0   \n",
       "2               2             600000.0                  4.0           0.0   \n",
       "3               3            1000000.0                  5.0           0.0   \n",
       "4               4             500000.0                  2.0       25000.0   \n",
       "...           ...                  ...                  ...           ...   \n",
       "86541       87015            1000000.0                  5.0       14500.0   \n",
       "86542       87016                  0.0                  0.0           0.0   \n",
       "86543       87017                  0.0                  0.0           0.0   \n",
       "86544       87018             800000.0                  5.0       13660.0   \n",
       "86545       87019                  0.0                  0.0           0.0   \n",
       "\n",
       "       Mobile_Verified  Var5  Loan_Amount_Submitted  Loan_Tenure_Submitted  \\\n",
       "0                    0     0                    5.0                    0.0   \n",
       "1                    1    13                    2.0                    2.0   \n",
       "2                    1     0                    4.0                    4.0   \n",
       "3                    1    10                    5.0                    5.0   \n",
       "4                    1    17                    2.0                    2.0   \n",
       "...                ...   ...                    ...                    ...   \n",
       "86541                0     9                    5.0                    0.0   \n",
       "86542                1     1                    0.0                    4.0   \n",
       "86543                1     8                    0.0                    4.0   \n",
       "86544                1    18                    5.0                    5.0   \n",
       "86545                1    12                    0.0                    4.0   \n",
       "\n",
       "       Interest_Rate  Processing_Fee  ...  Var1_cat_II  Var1_cat_III  \\\n",
       "0               0.00             0.0  ...            0             1   \n",
       "1              13.25             0.0  ...            0             0   \n",
       "2               0.00             0.0  ...            0             1   \n",
       "3               0.00             0.0  ...            0             1   \n",
       "4               0.00             0.0  ...            0             1   \n",
       "...              ...             ...  ...          ...           ...   \n",
       "86541           0.00             0.0  ...            0             1   \n",
       "86542          35.50          4800.0  ...            0             1   \n",
       "86543           0.00             0.0  ...            0             1   \n",
       "86544           0.00             0.0  ...            0             1   \n",
       "86545          13.99          3450.0  ...            0             0   \n",
       "\n",
       "       Var2_cat_I  Var2_cat_II  Var4_cat_I  Var4_cat_II  Var4_cat_III  \\\n",
       "0               0            1           0            0             1   \n",
       "1               0            1           0            1             0   \n",
       "2               1            0           0            0             1   \n",
       "3               1            0           0            1             0   \n",
       "4               1            0           0            1             0   \n",
       "...           ...          ...         ...          ...           ...   \n",
       "86541           0            1           0            1             0   \n",
       "86542           0            1           1            0             0   \n",
       "86543           0            1           0            1             0   \n",
       "86544           0            1           0            1             0   \n",
       "86545           0            1           0            1             0   \n",
       "\n",
       "       Source_cat_I  Source_cat_II  Source_cat_III  \n",
       "0                 0              1               0  \n",
       "1                 0              1               0  \n",
       "2                 0              1               0  \n",
       "3                 0              1               0  \n",
       "4                 0              1               0  \n",
       "...             ...            ...             ...  \n",
       "86541             0              1               0  \n",
       "86542             0              1               0  \n",
       "86543             0              1               0  \n",
       "86544             0              1               0  \n",
       "86545             0              1               0  \n",
       "\n",
       "[86546 rows x 36 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Data/data_processed.csv')\n",
    "print(data.shape)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 86546 entries, 0 to 86545\n",
      "Data columns (total 35 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Loan_Amount_Applied    86546 non-null  float64\n",
      " 1   Loan_Tenure_Applied    86546 non-null  float64\n",
      " 2   Existing_EMI           86546 non-null  float64\n",
      " 3   Mobile_Verified        86546 non-null  int64  \n",
      " 4   Var5                   86546 non-null  int64  \n",
      " 5   Loan_Amount_Submitted  86546 non-null  float64\n",
      " 6   Loan_Tenure_Submitted  86546 non-null  float64\n",
      " 7   Interest_Rate          86546 non-null  float64\n",
      " 8   Processing_Fee         86546 non-null  float64\n",
      " 9   EMI_Loan_Submitted     86546 non-null  float64\n",
      " 10  Filled_Form            86546 non-null  int64  \n",
      " 11  Disbursed              86546 non-null  int64  \n",
      " 12  Cty_cat_I              86546 non-null  int64  \n",
      " 13  Cty_cat_II             86546 non-null  int64  \n",
      " 14  Cty_cat_III            86546 non-null  int64  \n",
      " 15  Cty_cat_IV             86546 non-null  int64  \n",
      " 16  Cty_cat_V              86546 non-null  int64  \n",
      " 17  Age                    86546 non-null  int64  \n",
      " 18  Mntly_Incm_log         86546 non-null  float64\n",
      " 19  Employer_cat           86546 non-null  int64  \n",
      " 20  Male                   86546 non-null  int64  \n",
      " 21  Wb_brwsr               86546 non-null  int64  \n",
      " 22  Missing_LAA            86546 non-null  int64  \n",
      " 23  Missing_LTA            86546 non-null  int64  \n",
      " 24  Var1_cat_I             86546 non-null  int64  \n",
      " 25  Var1_cat_II            86546 non-null  int64  \n",
      " 26  Var1_cat_III           86546 non-null  int64  \n",
      " 27  Var2_cat_I             86546 non-null  int64  \n",
      " 28  Var2_cat_II            86546 non-null  int64  \n",
      " 29  Var4_cat_I             86546 non-null  int64  \n",
      " 30  Var4_cat_II            86546 non-null  int64  \n",
      " 31  Var4_cat_III           86546 non-null  int64  \n",
      " 32  Source_cat_I           86546 non-null  int64  \n",
      " 33  Source_cat_II          86546 non-null  int64  \n",
      " 34  Source_cat_III         86546 non-null  int64  \n",
      "dtypes: float64(9), int64(26)\n",
      "memory usage: 23.1 MB\n"
     ]
    }
   ],
   "source": [
    "del data['Unnamed: 0']\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divides the sample into a test and training part. Due to the unbalanced classes, I use the 'stratify' attribute so that the distribution of Y for the two samples are similar. \n",
    "Proportion - Disbursed: 0 to Disbursed: 1 is 67/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (86546, 34) y.shape: (86546,)\n"
     ]
    }
   ],
   "source": [
    "y = data['Disbursed'].astype(\"category\")\n",
    "X = data.drop('Disbursed',axis=1)\n",
    "print(\"X.shape: {} y.shape: {}\".format(X.shape, y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the feature_names later in the zip function. It will be used to pair with the list. The list of columns will be compared and assigned to the list from BorutaPy, which will identify the appropriate columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Loan_Amount_Applied', 'Loan_Tenure_Applied', 'Existing_EMI',\n",
       "       'Mobile_Verified', 'Var5', 'Loan_Amount_Submitted',\n",
       "       'Loan_Tenure_Submitted', 'Interest_Rate', 'Processing_Fee',\n",
       "       'EMI_Loan_Submitted', 'Filled_Form', 'Cty_cat_I', 'Cty_cat_II',\n",
       "       'Cty_cat_III', 'Cty_cat_IV', 'Cty_cat_V', 'Age', 'Mntly_Incm_log',\n",
       "       'Employer_cat', 'Male', 'Wb_brwsr', 'Missing_LAA', 'Missing_LTA',\n",
       "       'Var1_cat_I', 'Var1_cat_II', 'Var1_cat_III', 'Var2_cat_I',\n",
       "       'Var2_cat_II', 'Var4_cat_I', 'Var4_cat_II', 'Var4_cat_III',\n",
       "       'Source_cat_I', 'Source_cat_II', 'Source_cat_III'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = np.array(X.columns)\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data standardize using Standard Scaler to transform data columns values to certain ranges.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divides the sample into a test and training part. Due to the unbalanced classes, I use the 'stratify' attribute so that the distribution of the expense variable for the two samples are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=data[\"Disbursed\"],\n",
    "                                                    test_size=0.2, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train.value_counts: \n",
      "0    68219\n",
      "1     1017\n",
      "Name: Disbursed, dtype: int64 \n",
      "y_test.value_counts: \n",
      "0    17056\n",
      "1      254\n",
      "Name: Disbursed, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"y_train.value_counts: \\n{} \\ny_test.value_counts: \\n{}\".format(y_train.value_counts(), y_test.value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing nonsignificant variables using BorutaPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boruta is an all-relevant feature selection method. It tries to capture all the important, interesting features you might have in your dataset with respect to an outcome variable. Classifier will be trained on our dataset, such that we get importances for each of our features. Tree ensemble methods such as Random Forest can capture non-linear highly intricate relationships between our predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1, class_weight={0: 1, 1: 10}, max_depth=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from boruta import BorutaPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_selector = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=48, max_iter=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 15\n",
      "Confirmed: \t0\n",
      "Tentative: \t34\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 15\n",
      "Confirmed: \t0\n",
      "Tentative: \t34\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 15\n",
      "Confirmed: \t0\n",
      "Tentative: \t34\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 15\n",
      "Confirmed: \t0\n",
      "Tentative: \t34\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 15\n",
      "Confirmed: \t0\n",
      "Tentative: \t34\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 15\n",
      "Confirmed: \t0\n",
      "Tentative: \t34\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 15\n",
      "Confirmed: \t0\n",
      "Tentative: \t34\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 15\n",
      "Confirmed: \t11\n",
      "Tentative: \t6\n",
      "Rejected: \t17\n",
      "Iteration: \t9 / 15\n",
      "Confirmed: \t11\n",
      "Tentative: \t6\n",
      "Rejected: \t17\n",
      "Iteration: \t10 / 15\n",
      "Confirmed: \t11\n",
      "Tentative: \t6\n",
      "Rejected: \t17\n",
      "Iteration: \t11 / 15\n",
      "Confirmed: \t11\n",
      "Tentative: \t6\n",
      "Rejected: \t17\n",
      "Iteration: \t12 / 15\n",
      "Confirmed: \t11\n",
      "Tentative: \t3\n",
      "Rejected: \t20\n",
      "Iteration: \t13 / 15\n",
      "Confirmed: \t11\n",
      "Tentative: \t3\n",
      "Rejected: \t20\n",
      "Iteration: \t14 / 15\n",
      "Confirmed: \t11\n",
      "Tentative: \t3\n",
      "Rejected: \t20\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t15 / 15\n",
      "Confirmed: \t11\n",
      "Tentative: \t1\n",
      "Rejected: \t20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BorutaPy(estimator=RandomForestClassifier(class_weight={0: 1, 1: 10},\n",
       "                                          max_depth=6, n_estimators=88,\n",
       "                                          n_jobs=-1,\n",
       "                                          random_state=RandomState(MT19937) at 0x17EE521C340),\n",
       "         max_iter=15, n_estimators='auto',\n",
       "         random_state=RandomState(MT19937) at 0x17EE521C340, verbose=2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: Loan_Amount_Applied       Rank: 1   , Keep: True\n",
      "Feature: Loan_Tenure_Applied       Rank: 3   , Keep: False\n",
      "Feature: Existing_EMI              Rank: 1   , Keep: True\n",
      "Feature: Mobile_Verified           Rank: 8   , Keep: False\n",
      "Feature: Var5                      Rank: 1   , Keep: True\n",
      "Feature: Loan_Amount_Submitted     Rank: 4   , Keep: False\n",
      "Feature: Loan_Tenure_Submitted     Rank: 1   , Keep: True\n",
      "Feature: Interest_Rate             Rank: 1   , Keep: True\n",
      "Feature: Processing_Fee            Rank: 2   , Keep: False\n",
      "Feature: EMI_Loan_Submitted        Rank: 1   , Keep: True\n",
      "Feature: Filled_Form               Rank: 8   , Keep: False\n",
      "Feature: Cty_cat_I                 Rank: 20  , Keep: False\n",
      "Feature: Cty_cat_II                Rank: 16  , Keep: False\n",
      "Feature: Cty_cat_III               Rank: 22  , Keep: False\n",
      "Feature: Cty_cat_IV                Rank: 21  , Keep: False\n",
      "Feature: Cty_cat_V                 Rank: 14  , Keep: False\n",
      "Feature: Age                       Rank: 1   , Keep: True\n",
      "Feature: Mntly_Incm_log            Rank: 1   , Keep: True\n",
      "Feature: Employer_cat              Rank: 17  , Keep: False\n",
      "Feature: Male                      Rank: 5   , Keep: False\n",
      "Feature: Wb_brwsr                  Rank: 16  , Keep: False\n",
      "Feature: Missing_LAA               Rank: 11  , Keep: False\n",
      "Feature: Missing_LTA               Rank: 10  , Keep: False\n",
      "Feature: Var1_cat_I                Rank: 1   , Keep: True\n",
      "Feature: Var1_cat_II               Rank: 12  , Keep: False\n",
      "Feature: Var1_cat_III              Rank: 1   , Keep: True\n",
      "Feature: Var2_cat_I                Rank: 18  , Keep: False\n",
      "Feature: Var2_cat_II               Rank: 19  , Keep: False\n",
      "Feature: Var4_cat_I                Rank: 3   , Keep: False\n",
      "Feature: Var4_cat_II               Rank: 9   , Keep: False\n",
      "Feature: Var4_cat_III              Rank: 6   , Keep: False\n",
      "Feature: Source_cat_I              Rank: 23  , Keep: False\n",
      "Feature: Source_cat_II             Rank: 1   , Keep: True\n",
      "Feature: Source_cat_III            Rank: 14  , Keep: False\n"
     ]
    }
   ],
   "source": [
    "X_filtered = feat_selector.transform(X_train)\n",
    "feature_ranks = list(zip(feature_names, feat_selector.ranking_, feat_selector.support_))\n",
    "\n",
    "for feat in feature_ranks:\n",
    "    print('Feature: {:<25} Rank: {:<4}, Keep: {}'.format(feat[0], feat[1], feat[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69236, 11)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use DecisionTreeClassifier to evaluate the importance of the features (feature_importances_) in a importance classification task and compare it to the RandomForestClassifier results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9696707105719238"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)\n",
    "dtc.feature_importances_[dtc.feature_importances_>0.017]\n",
    "accuracy_score(y_test, dtc.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.bar(feature_names, dtc.feature_importances_)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, tree collection methods such as Random Forest and Decision Tree Classifier yield similar results on validity. I decide to stick to the columns previously selected with BorutaPy (X_filtered)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below is a definition of a function that will draw a confusion matrix in a simple form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_conf(a):\n",
    "    a_list=a.tolist()\n",
    "    a_list[0].insert(0,'Real 0')\n",
    "    a_list[1].insert(0,'Real 1')\n",
    "    print (tabulate (a_list,headers=['Real/Pred','Pred 0', 'Pred 1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree, Random Forest, Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          68219         0\n",
      "Real 1             44       973\n",
      "F1: 0.9778894472361809\n",
      "AUC:  0.9999858097705258\n"
     ]
    }
   ],
   "source": [
    "model_1 = DecisionTreeClassifier()\n",
    "model_1.fit(X_filtered, y_train)\n",
    "y_pred = model_1.predict_proba(X_filtered)[:,1]\n",
    "predictions = np.where(y_pred>0.5,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          68217         2\n",
      "Real 1             46       971\n",
      "F1: 0.9758793969849245\n",
      "AUC:  0.9999745094760536\n"
     ]
    }
   ],
   "source": [
    "model_2 = RandomForestClassifier()\n",
    "model_2.fit(X_filtered, y_train)\n",
    "y_pred = model_2.predict_proba(X_filtered)[:,1]\n",
    "predictions = np.where(y_pred>0.5,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          68212         7\n",
      "Real 1           1016         1\n",
      "F1: 0.001951219512195122\n",
      "AUC:  0.8099223950835763\n"
     ]
    }
   ],
   "source": [
    "model_3 = LogisticRegression()\n",
    "model_3.fit(X_filtered, y_train)\n",
    "y_pred = model_3.predict_proba(X_filtered)[:,1]\n",
    "predictions = np.where(y_pred>0.5,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters for the above models were adjusted by testing. \n",
    "### Below we will apply grid searching to find the best parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are symptoms of overfitting in tree models. To fix this, we will add a constraint like min_samples_leaf for this particular model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate of DecisionTreeClassifier: 0.963256 using {'ccp_alpha': 0.0, 'class_weight': 'balanced', 'criterion': 'entropy', 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# grid searching key hyperparametres for logistic regression\n",
    "\n",
    "# define models and parameters\n",
    "dt_model = DecisionTreeClassifier(min_samples_leaf=2)\n",
    "criterion = [\"gini\", \"entropy\"]\n",
    "splitter = [\"best\", \"random\"]\n",
    "class_weight = [\"{0: 2, 1: 1}\",\"{0: 1, 1: 2}\",\"balanced\"]\n",
    "ccp_alpha = [0.0, 0.01, 0.1]\n",
    "# define grid search\n",
    "grid = dict(criterion=criterion,splitter=splitter,class_weight=class_weight,ccp_alpha=ccp_alpha)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=dt_model, param_grid=grid, n_jobs=-1, cv=cv, \n",
    "                           scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_filtered, y_train)\n",
    "# summarize results\n",
    "print(\"Accuracy rate of DecisionTreeClassifier: %f using %s\" % (grid_result.best_score_, \n",
    "                                                                grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          67578       641\n",
      "Real 1              0      1017\n",
      "F1: 0.760373831775701\n",
      "AUC:  0.997898404673721\n"
     ]
    }
   ],
   "source": [
    "model_1 = DecisionTreeClassifier(ccp_alpha=0.0, class_weight='balanced', criterion='entropy', \n",
    "                                 min_samples_leaf=2, splitter='best')\n",
    "model_1.fit(X_filtered, y_train)\n",
    "y_pred = model_1.predict_proba(X_filtered)[:,1]\n",
    "predictions = np.where(y_pred>0.5,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate of RandomForestClassifier: 0.985292 using {'class_weight': {0: 1, 1: 2}, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# define models and parameters\n",
    "rf_model = RandomForestClassifier(min_samples_leaf=3)\n",
    "n_estimators = [50, 200]\n",
    "class_weight = [ \"balanced\", {0: 1, 1: 2}, {0: 1, 1: 3}]\n",
    "# define grid search\n",
    "grid = dict(n_estimators=n_estimators,class_weight=class_weight)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=grid, n_jobs=-1, cv=cv, \n",
    "                           scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_filtered, y_train)\n",
    "# summarize results\n",
    "print(\"Accuracy rate of RandomForestClassifier: %f using %s\" % (grid_result.best_score_, \n",
    "                                                                grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          68219         0\n",
      "Real 1            952        65\n",
      "F1: 0.12014787430683917\n",
      "AUC:  0.9994720643676304\n"
     ]
    }
   ],
   "source": [
    "model_2 = RandomForestClassifier(n_estimators=200, class_weight={0: 1, 1: 2}, criterion = \"gini\", \n",
    "                                 min_samples_leaf=3)\n",
    "model_2.fit(X_filtered, y_train)\n",
    "y_pred = model_2.predict_proba(X_filtered)[:,1]\n",
    "predictions = np.where(y_pred>0.5,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate of Logistic Regression: 0.985311 using {'C': 0.0001, 'class_weight': '{0: 1, 1: 10}', 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "# define models and parameters\n",
    "lr_model = LogisticRegression(max_iter=300)\n",
    "solvers = ['liblinear', 'lbfgs','newton-cg']\n",
    "penalty=['l2', 'l1']\n",
    "class_weight = [\"{0: 1, 1: 10}\",\"{0: 2, 1: 1}\",\"{0: 1, 1: 2}\",\"balanced\"]\n",
    "c_values = [0.01, 0.001, 0.0001]\n",
    "# define grid search\n",
    "grid = dict(solver=solvers,penalty=penalty,C=c_values,class_weight=class_weight)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=lr_model, param_grid=grid, n_jobs=-1, cv=cv, \n",
    "                           scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_filtered, y_train)\n",
    "# summarize results\n",
    "print(\"Accuracy rate of Logistic Regression: %f using %s\" % (grid_result.best_score_, \n",
    "                                                             grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          68059       160\n",
      "Real 1            998        19\n",
      "F1: 0.03177257525083612\n",
      "AUC:  0.8117596442355965\n"
     ]
    }
   ],
   "source": [
    "model_3 = LogisticRegression(C=0.0001, class_weight={0: 1, 1: 10}, penalty='l2', solver='lbfgs', \n",
    "                             max_iter=300, n_jobs=12)\n",
    "model_3.fit(X_filtered, y_train)\n",
    "y_pred = model_3.predict_proba(X_filtered)[:,1]\n",
    "predictions = np.where(y_pred>0.5,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:08:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy rate of Logistic Regression: 0.985075 using {'num_parallel_tree': 10}\n"
     ]
    }
   ],
   "source": [
    "# define models and parameters\n",
    "xgb_model = XGBClassifier(use_label_encoder=False)\n",
    "num_parallel_tree = [10, 40]\n",
    "# define grid search\n",
    "grid = dict(num_parallel_tree=num_parallel_tree)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=grid, n_jobs=-1, cv=cv, \n",
    "                           scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_filtered, y_train)\n",
    "# summarize results\n",
    "print(\"Accuracy rate of Logistic Regression: %f using %s\" % (grid_result.best_score_, \n",
    "                                                             grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:08:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          68219         0\n",
      "Real 1            924        93\n",
      "F1: 0.16756756756756755\n",
      "AUC:  0.9616529912203775\n"
     ]
    }
   ],
   "source": [
    "model_4 = XGBClassifier(use_label_encoder=False, n_estimators=100, num_parallel_tree=10)       \n",
    "model_4.fit(X_filtered, y_train)\n",
    "y_pred = model_4.predict_proba(X_filtered)[:,1]\n",
    "predictions = np.where(y_pred>0.5,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final establishing the best cut off threshold in terms of F1 score while using best params in a for loop. The best model will be one with the best F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7584, 0.7584, 0.7584, 0.7584, 0.7584, 0.7584, 0.7584, 0.7584, 0.7584, 0.7608]\n",
      "DecisionTreeClassifier Best F1: 0.7608 threshold: 0.9\n",
      "[0.039, 0.4824, 0.875, 0.8062, 0.395, 0.1184, 0.0175, 0.0, 0.0, 0.0]\n",
      "RandomForestClassifier Best F1: 0.875 threshold: 0.2\n",
      "[0.029, 0.0597, 0.0931, 0.115, 0.0788, 0.0318, 0.0183, 0.0057, 0.0039, 0.002]\n",
      "LogisticRegression Best F1: 0.115 threshold: 0.30000000000000004\n",
      "[03:08:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0.029, 0.4768, 0.5033, 0.3824, 0.2596, 0.1676, 0.0973, 0.0517, 0.0098, 0.0]\n",
      "XGBClassifier Best F1: 0.5033 threshold: 0.2\n"
     ]
    }
   ],
   "source": [
    "models_Params_Tresholds = [DecisionTreeClassifier(ccp_alpha=0.0, class_weight='balanced', \n",
    "                                                  criterion='entropy', min_samples_leaf=2, \n",
    "                                                  splitter='best'),\n",
    "                           RandomForestClassifier(n_estimators=200, class_weight={0: 1, 1: 2}, \n",
    "                                                  criterion = \"gini\", min_samples_leaf=3),\n",
    "                           LogisticRegression(C=0.0001, class_weight={0: 1, 1: 10}, penalty='l2', \n",
    "                                              solver='lbfgs', max_iter=300,n_jobs=12),\n",
    "                           XGBClassifier(use_label_encoder=False, n_estimators=100, num_parallel_tree=10)]\n",
    "m = ['DecisionTreeClassifier','RandomForestClassifier','LogisticRegression', 'XGBClassifier']\n",
    "i = 0\n",
    "for model in models_Params_Tresholds:    \n",
    "    model.fit(X_filtered, y_train)\n",
    "    y_pred = model.predict_proba(X_filtered)[:,1]\n",
    "    r = []\n",
    "    for x in np.arange(0,1,0.1):\n",
    "        z = np.where(y_pred > x,1,0)\n",
    "        f = f1_score(y_train, z)\n",
    "        r.append(round(f,4))\n",
    "    print(r)    \n",
    "    print(m[i], \"Best F1:\", np.max(r),\"threshold:\" ,np.argmax(r)*0.1)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will search more broadly around the value of 0.2 threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4838, 0.5404, 0.5936, 0.6449, 0.6961, 0.7405, 0.7765, 0.8092, 0.8387, 0.862, 0.8812, 0.8927, 0.9008, 0.905, 0.9035, 0.9009, 0.8932, 0.8784, 0.8632, 0.8331]\n",
      "RandomForestClassifier  Best F1: 0.905 threshold: 0.23\n"
     ]
    }
   ],
   "source": [
    "models_Params_Tresholds = [RandomForestClassifier(n_estimators=200, class_weight={0: 1, 1: 2}, \n",
    "                                                  criterion = \"gini\", min_samples_leaf=3)]\n",
    "\n",
    "for model in models_Params_Tresholds:    \n",
    "    model.fit(X_filtered, y_train)\n",
    "    y_pred = model.predict_proba(X_filtered)[:,1]\n",
    "    r = []\n",
    "    for x in np.arange(0.1,0.3,0.01):\n",
    "        z = np.where(y_pred > x,1,0)\n",
    "        f = f1_score(y_train, z)\n",
    "        r.append(round(f,4))\n",
    "    print(r)    \n",
    "    print('RandomForestClassifier ', \"Best F1:\", np.max(r),\"threshold:\" ,np.argmax(r)*0.01+0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          67586       633\n",
      "Real 1              1      1016\n",
      "F1: 0.7621905476369093\n",
      "AUC:  0.9978855404992104\n"
     ]
    }
   ],
   "source": [
    "print('DecisionTreeClassifier')\n",
    "threshold = 0.9\n",
    "\n",
    "model_1 = DecisionTreeClassifier(ccp_alpha=0.0, class_weight='balanced', criterion='entropy', \n",
    "                                 min_samples_leaf=2, splitter='best')\n",
    "model_1.fit(X_filtered, y_train)\n",
    "y_pred = model_1.predict_proba(X_filtered)[:,1]\n",
    "predictions = np.where(y_pred>threshold,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          68066       153\n",
      "Real 1             45       972\n",
      "F1: 0.907563025210084\n",
      "AUC:  0.9995099866568602\n"
     ]
    }
   ],
   "source": [
    "print('RandomForestClassifier')\n",
    "threshold = 0.23\n",
    "\n",
    "model_2 = RandomForestClassifier(n_estimators=200, class_weight={0: 1, 1: 2},criterion = \"gini\",\n",
    "                                 min_samples_leaf=3)\n",
    "model_2.fit(X_filtered, y_train)\n",
    "y_pred = model_2.predict_proba(X_filtered)[:,1]\n",
    "predictions = np.where(y_pred>threshold,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          65399      2820\n",
      "Real 1            783       234\n",
      "F1: 0.11495946941783344\n",
      "AUC:  0.8117596442355965\n"
     ]
    }
   ],
   "source": [
    "print('LogisticRegression')\n",
    "threshold = 0.3\n",
    "\n",
    "model_3 = LogisticRegression(C=0.0001, class_weight={0: 1, 1: 10}, penalty='l2', solver='lbfgs',\n",
    "                                              max_iter=300,n_jobs=12)\n",
    "model_3.fit(X_filtered, y_train)\n",
    "y_pred = model_3.predict_proba(X_filtered)[:,1]\n",
    "predictions = np.where(y_pred>threshold,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "[03:09:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          68112       107\n",
      "Real 1            639       378\n",
      "F1: 0.5033288948069241\n",
      "AUC:  0.9616529912203775\n"
     ]
    }
   ],
   "source": [
    "print('XGBClassifier')\n",
    "threshold = 0.2\n",
    "\n",
    "model_4 = XGBClassifier(use_label_encoder=False, n_estimators=100, num_parallel_tree=10)\n",
    "model_4.fit(X_filtered, y_train)\n",
    "y_pred = model_4.predict_proba(X_filtered)[:,1]\n",
    "predictions = np.where(y_pred>threshold,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          17042        14\n",
      "Real 1             14       240\n",
      "F1: 0.9448818897637795\n",
      "AUC:  0.9996679534576236\n"
     ]
    }
   ],
   "source": [
    "print('RandomForestClassifier')\n",
    "threshold = 0.23\n",
    "\n",
    "model_2 = RandomForestClassifier(n_estimators=200, class_weight={0: 1, 1: 2},criterion = \"gini\",\n",
    "                                 min_samples_leaf=3)\n",
    "model_2.fit(X_test, y_test)\n",
    "y_pred = model_2.predict_proba(X_test)[:,1]\n",
    "predictions = np.where(y_pred>threshold,1,0)\n",
    "print_conf(confusion_matrix(y_test, predictions))\n",
    "print(\"F1:\",f1_score(y_test, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, RandomForestClassifier gives us the best F1 score and the best true positive coefficient with an acceptable error rate. The data was prepared using tree methods. The model was well received with a large number of categorical values dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestClassifier(n_estimators = 200, class_weight = {0: 1, 1: 2}, criterion = \"gini\", min_samples_leaf = 3)\n",
    "\n",
    "treshold = 0.23\n",
    "\n",
    "F1: 0.94488\n",
    "\n",
    "AUC:  0.99967"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

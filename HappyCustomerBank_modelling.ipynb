{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, roc_curve, confusion_matrix, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from tabulate import tabulate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86546, 36)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Loan_Amount_Applied</th>\n",
       "      <th>Loan_Tenure_Applied</th>\n",
       "      <th>Existing_EMI</th>\n",
       "      <th>Mobile_Verified</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Loan_Amount_Submitted</th>\n",
       "      <th>Loan_Tenure_Submitted</th>\n",
       "      <th>Interest_Rate</th>\n",
       "      <th>Processing_Fee</th>\n",
       "      <th>...</th>\n",
       "      <th>Var1_cat_II</th>\n",
       "      <th>Var1_cat_III</th>\n",
       "      <th>Var2_cat_I</th>\n",
       "      <th>Var2_cat_II</th>\n",
       "      <th>Var4_cat_I</th>\n",
       "      <th>Var4_cat_II</th>\n",
       "      <th>Var4_cat_III</th>\n",
       "      <th>Source_cat_I</th>\n",
       "      <th>Source_cat_II</th>\n",
       "      <th>Source_cat_III</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86541</th>\n",
       "      <td>87015</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86542</th>\n",
       "      <td>87016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35.50</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86543</th>\n",
       "      <td>87017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86544</th>\n",
       "      <td>87018</td>\n",
       "      <td>800000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13660.0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86545</th>\n",
       "      <td>87019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.99</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86546 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Loan_Amount_Applied  Loan_Tenure_Applied  Existing_EMI  \\\n",
       "0               0             300000.0                  5.0           0.0   \n",
       "1               1             200000.0                  2.0           0.0   \n",
       "2               2             600000.0                  4.0           0.0   \n",
       "3               3            1000000.0                  5.0           0.0   \n",
       "4               4             500000.0                  2.0       25000.0   \n",
       "...           ...                  ...                  ...           ...   \n",
       "86541       87015            1000000.0                  5.0       14500.0   \n",
       "86542       87016                  0.0                  0.0           0.0   \n",
       "86543       87017                  0.0                  0.0           0.0   \n",
       "86544       87018             800000.0                  5.0       13660.0   \n",
       "86545       87019                  0.0                  0.0           0.0   \n",
       "\n",
       "       Mobile_Verified  Var5  Loan_Amount_Submitted  Loan_Tenure_Submitted  \\\n",
       "0                    0     0                    5.0                    0.0   \n",
       "1                    1    13                    2.0                    2.0   \n",
       "2                    1     0                    4.0                    4.0   \n",
       "3                    1    10                    5.0                    5.0   \n",
       "4                    1    17                    2.0                    2.0   \n",
       "...                ...   ...                    ...                    ...   \n",
       "86541                0     9                    5.0                    0.0   \n",
       "86542                1     1                    0.0                    4.0   \n",
       "86543                1     8                    0.0                    4.0   \n",
       "86544                1    18                    5.0                    5.0   \n",
       "86545                1    12                    0.0                    4.0   \n",
       "\n",
       "       Interest_Rate  Processing_Fee  ...  Var1_cat_II  Var1_cat_III  \\\n",
       "0               0.00             0.0  ...            0             1   \n",
       "1              13.25             0.0  ...            0             0   \n",
       "2               0.00             0.0  ...            0             1   \n",
       "3               0.00             0.0  ...            0             1   \n",
       "4               0.00             0.0  ...            0             1   \n",
       "...              ...             ...  ...          ...           ...   \n",
       "86541           0.00             0.0  ...            0             1   \n",
       "86542          35.50          4800.0  ...            0             1   \n",
       "86543           0.00             0.0  ...            0             1   \n",
       "86544           0.00             0.0  ...            0             1   \n",
       "86545          13.99          3450.0  ...            0             0   \n",
       "\n",
       "       Var2_cat_I  Var2_cat_II  Var4_cat_I  Var4_cat_II  Var4_cat_III  \\\n",
       "0               0            1           0            0             1   \n",
       "1               0            1           0            1             0   \n",
       "2               1            0           0            0             1   \n",
       "3               1            0           0            1             0   \n",
       "4               1            0           0            1             0   \n",
       "...           ...          ...         ...          ...           ...   \n",
       "86541           0            1           0            1             0   \n",
       "86542           0            1           1            0             0   \n",
       "86543           0            1           0            1             0   \n",
       "86544           0            1           0            1             0   \n",
       "86545           0            1           0            1             0   \n",
       "\n",
       "       Source_cat_I  Source_cat_II  Source_cat_III  \n",
       "0                 0              1               0  \n",
       "1                 0              1               0  \n",
       "2                 0              1               0  \n",
       "3                 0              1               0  \n",
       "4                 0              1               0  \n",
       "...             ...            ...             ...  \n",
       "86541             0              1               0  \n",
       "86542             0              1               0  \n",
       "86543             0              1               0  \n",
       "86544             0              1               0  \n",
       "86545             0              1               0  \n",
       "\n",
       "[86546 rows x 36 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Data/data_processed.csv')\n",
    "print(data.shape)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 86546 entries, 0 to 86545\n",
      "Data columns (total 35 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Loan_Amount_Applied    86546 non-null  float64\n",
      " 1   Loan_Tenure_Applied    86546 non-null  float64\n",
      " 2   Existing_EMI           86546 non-null  float64\n",
      " 3   Mobile_Verified        86546 non-null  int64  \n",
      " 4   Var5                   86546 non-null  int64  \n",
      " 5   Loan_Amount_Submitted  86546 non-null  float64\n",
      " 6   Loan_Tenure_Submitted  86546 non-null  float64\n",
      " 7   Interest_Rate          86546 non-null  float64\n",
      " 8   Processing_Fee         86546 non-null  float64\n",
      " 9   EMI_Loan_Submitted     86546 non-null  float64\n",
      " 10  Filled_Form            86546 non-null  int64  \n",
      " 11  Disbursed              86546 non-null  int64  \n",
      " 12  Cty_cat_I              86546 non-null  int64  \n",
      " 13  Cty_cat_II             86546 non-null  int64  \n",
      " 14  Cty_cat_III            86546 non-null  int64  \n",
      " 15  Cty_cat_IV             86546 non-null  int64  \n",
      " 16  Cty_cat_V              86546 non-null  int64  \n",
      " 17  Age                    86546 non-null  int64  \n",
      " 18  Mntly_Incm_log         86546 non-null  float64\n",
      " 19  Employer_cat           86546 non-null  int64  \n",
      " 20  Male                   86546 non-null  int64  \n",
      " 21  Wb_brwsr               86546 non-null  int64  \n",
      " 22  Missing_LAA            86546 non-null  int64  \n",
      " 23  Missing_LTA            86546 non-null  int64  \n",
      " 24  Var1_cat_I             86546 non-null  int64  \n",
      " 25  Var1_cat_II            86546 non-null  int64  \n",
      " 26  Var1_cat_III           86546 non-null  int64  \n",
      " 27  Var2_cat_I             86546 non-null  int64  \n",
      " 28  Var2_cat_II            86546 non-null  int64  \n",
      " 29  Var4_cat_I             86546 non-null  int64  \n",
      " 30  Var4_cat_II            86546 non-null  int64  \n",
      " 31  Var4_cat_III           86546 non-null  int64  \n",
      " 32  Source_cat_I           86546 non-null  int64  \n",
      " 33  Source_cat_II          86546 non-null  int64  \n",
      " 34  Source_cat_III         86546 non-null  int64  \n",
      "dtypes: float64(9), int64(26)\n",
      "memory usage: 23.1 MB\n"
     ]
    }
   ],
   "source": [
    "del data['Unnamed: 0']\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divides the sample into a test and training part. Due to the unbalanced classes, I use the 'stratify' attribute so that the distribution of Y for the two samples are similar. \n",
    "Proportion - Disbursed: 0 to Disbursed: 1 is 67/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (86546, 34) y.shape: (86546,)\n"
     ]
    }
   ],
   "source": [
    "y = data['Disbursed'].astype(\"category\")\n",
    "X = data.drop('Disbursed',axis=1)\n",
    "print(\"X.shape: {} y.shape: {}\".format(X.shape, y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the feature_names later in the zip function. It will be used to pair with the list. The list of columns will be compared and assigned to the list from BorutaPy, which will identify the appropriate columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Loan_Amount_Applied', 'Loan_Tenure_Applied', 'Existing_EMI',\n",
       "       'Mobile_Verified', 'Var5', 'Loan_Amount_Submitted',\n",
       "       'Loan_Tenure_Submitted', 'Interest_Rate', 'Processing_Fee',\n",
       "       'EMI_Loan_Submitted', 'Filled_Form', 'Cty_cat_I', 'Cty_cat_II',\n",
       "       'Cty_cat_III', 'Cty_cat_IV', 'Cty_cat_V', 'Age', 'Mntly_Incm_log',\n",
       "       'Employer_cat', 'Male', 'Wb_brwsr', 'Missing_LAA', 'Missing_LTA',\n",
       "       'Var1_cat_I', 'Var1_cat_II', 'Var1_cat_III', 'Var2_cat_I',\n",
       "       'Var2_cat_II', 'Var4_cat_I', 'Var4_cat_II', 'Var4_cat_III',\n",
       "       'Source_cat_I', 'Source_cat_II', 'Source_cat_III'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = np.array(X.columns)\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data standardize using Standard Scaler to transform data columns values to certain ranges.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divides the sample into a test and training part. Due to the unbalanced classes, I use the 'stratify' attribute so that the distribution of the expense variable for the two samples are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=data[\"Disbursed\"],\n",
    "                                                    test_size=0.2, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train.value_counts: \n",
      "0    68219\n",
      "1     1017\n",
      "Name: Disbursed, dtype: int64 \n",
      "y_test.value_counts: \n",
      "0    17056\n",
      "1      254\n",
      "Name: Disbursed, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"y_train.value_counts: \\n{} \\ny_test.value_counts: \\n{}\".format(y_train.value_counts(), y_test.value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing nonsignificant variables using BorutaPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boruta is an all-relevant feature selection method. It tries to capture all the important, interesting features you might have in your dataset with respect to an outcome variable. Classifier will be trained on our dataset, such that we get importances for each of our features. Tree ensemble methods such as Random Forest can capture non-linear highly intricate relationships between our predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1, class_weight={0: 1, 1: 10}, max_depth=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from boruta import BorutaPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_selector = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=48, max_iter=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 15\n",
      "Confirmed: \t0\n",
      "Tentative: \t34\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 15\n",
      "Confirmed: \t0\n",
      "Tentative: \t34\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 15\n",
      "Confirmed: \t0\n",
      "Tentative: \t34\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 15\n",
      "Confirmed: \t0\n",
      "Tentative: \t34\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 15\n",
      "Confirmed: \t0\n",
      "Tentative: \t34\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 15\n",
      "Confirmed: \t0\n",
      "Tentative: \t34\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 15\n",
      "Confirmed: \t0\n",
      "Tentative: \t34\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 15\n",
      "Confirmed: \t11\n",
      "Tentative: \t6\n",
      "Rejected: \t17\n",
      "Iteration: \t9 / 15\n",
      "Confirmed: \t11\n",
      "Tentative: \t6\n",
      "Rejected: \t17\n",
      "Iteration: \t10 / 15\n",
      "Confirmed: \t11\n",
      "Tentative: \t6\n",
      "Rejected: \t17\n",
      "Iteration: \t11 / 15\n",
      "Confirmed: \t11\n",
      "Tentative: \t6\n",
      "Rejected: \t17\n",
      "Iteration: \t12 / 15\n",
      "Confirmed: \t11\n",
      "Tentative: \t3\n",
      "Rejected: \t20\n",
      "Iteration: \t13 / 15\n",
      "Confirmed: \t11\n",
      "Tentative: \t3\n",
      "Rejected: \t20\n",
      "Iteration: \t14 / 15\n",
      "Confirmed: \t11\n",
      "Tentative: \t3\n",
      "Rejected: \t20\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t15 / 15\n",
      "Confirmed: \t11\n",
      "Tentative: \t1\n",
      "Rejected: \t20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BorutaPy(estimator=RandomForestClassifier(class_weight={0: 1, 1: 10},\n",
       "                                          max_depth=6, n_estimators=88,\n",
       "                                          n_jobs=-1,\n",
       "                                          random_state=RandomState(MT19937) at 0x25B920DA440),\n",
       "         max_iter=15, n_estimators='auto',\n",
       "         random_state=RandomState(MT19937) at 0x25B920DA440, verbose=2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: Loan_Amount_Applied       Rank: 1   , Keep: True\n",
      "Feature: Loan_Tenure_Applied       Rank: 3   , Keep: False\n",
      "Feature: Existing_EMI              Rank: 1   , Keep: True\n",
      "Feature: Mobile_Verified           Rank: 8   , Keep: False\n",
      "Feature: Var5                      Rank: 1   , Keep: True\n",
      "Feature: Loan_Amount_Submitted     Rank: 4   , Keep: False\n",
      "Feature: Loan_Tenure_Submitted     Rank: 1   , Keep: True\n",
      "Feature: Interest_Rate             Rank: 1   , Keep: True\n",
      "Feature: Processing_Fee            Rank: 2   , Keep: False\n",
      "Feature: EMI_Loan_Submitted        Rank: 1   , Keep: True\n",
      "Feature: Filled_Form               Rank: 8   , Keep: False\n",
      "Feature: Cty_cat_I                 Rank: 20  , Keep: False\n",
      "Feature: Cty_cat_II                Rank: 16  , Keep: False\n",
      "Feature: Cty_cat_III               Rank: 22  , Keep: False\n",
      "Feature: Cty_cat_IV                Rank: 21  , Keep: False\n",
      "Feature: Cty_cat_V                 Rank: 14  , Keep: False\n",
      "Feature: Age                       Rank: 1   , Keep: True\n",
      "Feature: Mntly_Incm_log            Rank: 1   , Keep: True\n",
      "Feature: Employer_cat              Rank: 17  , Keep: False\n",
      "Feature: Male                      Rank: 5   , Keep: False\n",
      "Feature: Wb_brwsr                  Rank: 16  , Keep: False\n",
      "Feature: Missing_LAA               Rank: 11  , Keep: False\n",
      "Feature: Missing_LTA               Rank: 10  , Keep: False\n",
      "Feature: Var1_cat_I                Rank: 1   , Keep: True\n",
      "Feature: Var1_cat_II               Rank: 12  , Keep: False\n",
      "Feature: Var1_cat_III              Rank: 1   , Keep: True\n",
      "Feature: Var2_cat_I                Rank: 18  , Keep: False\n",
      "Feature: Var2_cat_II               Rank: 19  , Keep: False\n",
      "Feature: Var4_cat_I                Rank: 3   , Keep: False\n",
      "Feature: Var4_cat_II               Rank: 9   , Keep: False\n",
      "Feature: Var4_cat_III              Rank: 6   , Keep: False\n",
      "Feature: Source_cat_I              Rank: 23  , Keep: False\n",
      "Feature: Source_cat_II             Rank: 1   , Keep: True\n",
      "Feature: Source_cat_III            Rank: 14  , Keep: False\n"
     ]
    }
   ],
   "source": [
    "X_filtered = feat_selector.transform(X_train)\n",
    "feature_ranks = list(zip(feature_names, feat_selector.ranking_, feat_selector.support_))\n",
    "\n",
    "for feat in feature_ranks:\n",
    "    print('Feature: {:<25} Rank: {:<4}, Keep: {}'.format(feat[0], feat[1], feat[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69236, 11)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use DecisionTreeClassifier to evaluate the importance of the features (feature_importances_) in a importance classification task and compare it to the RandomForestClassifier results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9698440207972271"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)\n",
    "dtc.feature_importances_[dtc.feature_importances_>0.017]\n",
    "accuracy_score(y_test, dtc.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.bar(feature_names, dtc.feature_importances_)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, tree collection methods such as Random Forest and Decision Tree Classifier yield similar results on validity. I decide to stick to the columns previously selected with BorutaPy (X_filtered)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below is a definition of a function that will draw a confusion matrix in a simple form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_conf(a):\n",
    "    a_list=a.tolist()\n",
    "    a_list[0].insert(0,'Real 0')\n",
    "    a_list[1].insert(0,'Real 1')\n",
    "    print (tabulate (a_list,headers=['Real/Pred','Pred 0', 'Pred 1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree, Random Forest, Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          67689       530\n",
      "Real 1            161       856\n",
      "F1: 0.7124427798585102\n",
      "AUC:  0.9963226261745983\n"
     ]
    }
   ],
   "source": [
    "model_1 = DecisionTreeClassifier(class_weight={0: 2, 1: 1}, min_samples_leaf=2)\n",
    "model_1.fit(X_filtered, y_train)\n",
    "y_pred = model_1.predict_proba(X_filtered)[:,1]\n",
    "predictions = np.where(y_pred>0.3,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          68171        48\n",
      "Real 1             38       979\n",
      "F1: 0.9579256360078278\n",
      "AUC:  0.9998228059054937\n"
     ]
    }
   ],
   "source": [
    "model_2 = RandomForestClassifier(n_estimators=100,class_weight={0: 1, 1: 2}, min_samples_leaf=2)\n",
    "model_2.fit(X_filtered, y_train)\n",
    "y_pred = model_2.predict_proba(X_filtered)[:,1]\n",
    "predictions = np.where(y_pred>0.3,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          62526      5693\n",
      "Real 1            627       390\n",
      "F1: 0.10985915492957747\n",
      "AUC:  0.8146317495639117\n"
     ]
    }
   ],
   "source": [
    "model_3 = LogisticRegression(C=1, class_weight={0: 1, 1: 10}, penalty='l2', solver='newton-cg', max_iter=300,\n",
    "                           n_jobs=12)\n",
    "model_3.fit(X_filtered, y_train)\n",
    "y_pred = model_3.predict_proba(X_filtered)[:,1]\n",
    "predictions = np.where(y_pred>0.3,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters for the above models were adjusted by testing. \n",
    "### Below we will apply grid searching to find the best parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate of DecisionTreeClassifier: 0.963092 using {'ccp_alpha': 0.0, 'class_weight': 'balanced', 'criterion': 'entropy', 'min_samples_leaf': 2, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# grid searching key hyperparametres for logistic regression\n",
    "\n",
    "# define models and parameters\n",
    "dt_model = DecisionTreeClassifier()\n",
    "criterion = [\"gini\", \"entropy\"]\n",
    "splitter = [\"best\", \"random\"]\n",
    "class_weight = [\"{0: 2, 1: 1}\",\"{0: 1, 1: 2}\",\"balanced\"]\n",
    "min_samples_leaf = [2,3,4,5]\n",
    "ccp_alpha = [0.0, 0.01, 0.1]\n",
    "# define grid search\n",
    "grid = dict(criterion=criterion,splitter=splitter,class_weight=class_weight,min_samples_leaf=min_samples_leaf,ccp_alpha=ccp_alpha)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=dt_model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_filtered, y_train)\n",
    "# summarize results\n",
    "print(\"Accuracy rate of DecisionTreeClassifier: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          67577       642\n",
      "Real 1              0      1017\n",
      "F1: 0.7600896860986547\n",
      "AUC:  0.99790203691123\n"
     ]
    }
   ],
   "source": [
    "model_1 = DecisionTreeClassifier(ccp_alpha=0.0, class_weight='balanced', criterion='entropy', \n",
    "                                 min_samples_leaf=2, splitter='best')\n",
    "model_1.fit(X_filtered, y_train)\n",
    "y_pred = model_1.predict_proba(X_filtered)[:,1]\n",
    "predictions = np.where(y_pred>0.3,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate of RandomForestClassifier: 0.984608 using {'class_weight': {0: 1, 1: 2}, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# define models and parameters\n",
    "rf_model = RandomForestClassifier()\n",
    "n_estimators = [50, 200]\n",
    "class_weight = [ \"balanced\", {0: 1, 1: 2}]\n",
    "# define grid search\n",
    "grid = dict(n_estimators=n_estimators,class_weight=class_weight)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_filtered, y_train)\n",
    "# summarize results\n",
    "print(\"Accuracy rate of RandomForestClassifier: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          68172        47\n",
      "Real 1              1      1016\n",
      "F1: 0.976923076923077\n",
      "AUC:  0.9999849593657122\n"
     ]
    }
   ],
   "source": [
    "model_2 = RandomForestClassifier(n_estimators=200, class_weight={0: 1, 1: 2}, criterion = \"gini\")\n",
    "model_2.fit(X_filtered, y_train)\n",
    "y_pred = model_2.predict_proba(X_filtered)[:,1]\n",
    "predictions = np.where(y_pred>0.3,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate of Logistic Regression: 0.985311 using {'C': 0.0001, 'class_weight': '{0: 1, 1: 10}', 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "# define models and parameters\n",
    "lr_model = LogisticRegression(max_iter=300)\n",
    "solvers = ['liblinear', 'lbfgs','newton-cg']\n",
    "penalty=['l2', 'l1']\n",
    "class_weight = [\"{0: 1, 1: 10}\",\"{0: 2, 1: 1}\",\"{0: 1, 1: 2}\",\"balanced\"]\n",
    "c_values = [0.01, 0.001, 0.0001]\n",
    "# define grid search\n",
    "grid = dict(solver=solvers,penalty=penalty,C=c_values,class_weight=class_weight)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=lr_model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_filtered, y_train)\n",
    "# summarize results\n",
    "print(\"Accuracy rate of Logistic Regression: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          65399      2820\n",
      "Real 1            783       234\n",
      "F1: 0.11495946941783344\n",
      "AUC:  0.8117596442355965\n"
     ]
    }
   ],
   "source": [
    "model_3 = LogisticRegression(C=0.0001, class_weight={0: 1, 1: 10}, penalty='l2', solver='lbfgs', max_iter=300,\n",
    "                           n_jobs=12)\n",
    "model_3.fit(X_filtered, y_train)\n",
    "y_pred = model_3.predict_proba(X_filtered)[:,1]\n",
    "predictions = np.where(y_pred>0.3,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:43:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy rate of Logistic Regression: 0.985075 using {'num_parallel_tree': 10}\n"
     ]
    }
   ],
   "source": [
    "# define models and parameters\n",
    "xgb_model = XGBClassifier(use_label_encoder=False)\n",
    "num_parallel_tree = [10, 40]\n",
    "# define grid search\n",
    "grid = dict(num_parallel_tree=num_parallel_tree)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_filtered, y_train)\n",
    "# summarize results\n",
    "print(\"Accuracy rate of Logistic Regression: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:43:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          68204        15\n",
      "Real 1            773       244\n",
      "F1: 0.3824451410658307\n",
      "AUC:  0.9616530056340183\n"
     ]
    }
   ],
   "source": [
    "model_4 = XGBClassifier(use_label_encoder=False, n_estimators=100, num_parallel_tree=40)                                                          \n",
    "model_4.fit(X_filtered, y_train)\n",
    "y_pred = model_4.predict_proba(X_filtered)[:,1]\n",
    "predictions = np.where(y_pred>0.3,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final establishing the best cut off threshold in terms of F1 score while using best params in a for loop. The best model will be one with the best F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7598, 0.7598, 0.7598, 0.7598, 0.7598, 0.7598, 0.7598, 0.7598, 0.7598, 0.7622]\n",
      "DecisionTreeClassifier Best F1: 0.7622 threshold: 0.9\n",
      "[0.0971, 0.8532, 0.9718, 0.9769, 0.9778, 0.9783, 0.9175, 0.1839, 0.0059, 0.0]\n",
      "RandomForestClassifier Best F1: 0.9783 threshold: 0.5\n",
      "[0.029, 0.0597, 0.0931, 0.115, 0.0788, 0.0318, 0.0183, 0.0057, 0.0039, 0.002]\n",
      "LogisticRegression Best F1: 0.115 threshold: 0.30000000000000004\n",
      "[23:44:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0.029, 0.4768, 0.5033, 0.3824, 0.2596, 0.1676, 0.0973, 0.0517, 0.0098, 0.0]\n",
      "XGBClassifier Best F1: 0.5033 threshold: 0.2\n"
     ]
    }
   ],
   "source": [
    "models_Params_Tresholds = [DecisionTreeClassifier(ccp_alpha=0.0, class_weight='balanced', criterion='entropy', \n",
    "                                                  min_samples_leaf=2, splitter='best'),\n",
    "                           RandomForestClassifier(n_estimators=200, class_weight={0: 1, 1: 2},criterion = \"gini\"),\n",
    "                           LogisticRegression(C=0.0001, class_weight={0: 1, 1: 10}, penalty='l2', solver='lbfgs',\n",
    "                                              max_iter=300,n_jobs=12),\n",
    "                           XGBClassifier(use_label_encoder=False, n_estimators=100, num_parallel_tree=40)]\n",
    "m = ['DecisionTreeClassifier','RandomForestClassifier','LogisticRegression', 'XGBClassifier']\n",
    "i = 0\n",
    "for model in models_Params_Tresholds:    \n",
    "    model.fit(X_filtered, y_train)\n",
    "    y_pred = model.predict_proba(X_filtered)[:,1]\n",
    "    r = []\n",
    "    for x in np.arange(0,1,0.1):\n",
    "        z = np.where(y_pred > x,1,0)\n",
    "        f = f1_score(y_train, z)\n",
    "        r.append(round(f,4))\n",
    "    print(r)    \n",
    "    print(m[i], \"Best F1:\", np.max(r),\"threshold:\" ,np.argmax(r)*0.1)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          67594       625\n",
      "Real 1              1      1016\n",
      "F1: 0.7644845748683221\n",
      "AUC:  0.9979193044530381\n"
     ]
    }
   ],
   "source": [
    "print('DecisionTreeClassifier')\n",
    "threshold = 0.9\n",
    "\n",
    "model_1 = DecisionTreeClassifier(ccp_alpha=0.0, class_weight='balanced', criterion='entropy', \n",
    "                                                  min_samples_leaf=2, splitter='best')\n",
    "model_1.fit(X_filtered, y_train)\n",
    "y_pred = model_1.predict_proba(X_filtered)[:,1]\n",
    "predictions = np.where(y_pred>threshold,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          68178        41\n",
      "Real 1              4      1013\n",
      "F1: 0.9782713664896185\n",
      "AUC:  0.9999845557837668\n"
     ]
    }
   ],
   "source": [
    "print('RandomForestClassifier')\n",
    "threshold = 0.4\n",
    "\n",
    "model_2 = RandomForestClassifier(n_estimators=200, class_weight={0: 1, 1: 2},criterion = \"gini\")\n",
    "model_2.fit(X_filtered, y_train)\n",
    "y_pred = model_2.predict_proba(X_filtered)[:,1]\n",
    "predictions = np.where(y_pred>threshold,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          65399      2820\n",
      "Real 1            783       234\n",
      "F1: 0.11495946941783344\n",
      "AUC:  0.8117596442355965\n"
     ]
    }
   ],
   "source": [
    "print('LogisticRegression')\n",
    "threshold = 0.3\n",
    "\n",
    "model_3 = LogisticRegression(C=0.0001, class_weight={0: 1, 1: 10}, penalty='l2', solver='lbfgs',\n",
    "                                              max_iter=300,n_jobs=12)\n",
    "model_3.fit(X_filtered, y_train)\n",
    "y_pred = model_3.predict_proba(X_filtered)[:,1]\n",
    "predictions = np.where(y_pred>threshold,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "[23:45:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          68112       107\n",
      "Real 1            639       378\n",
      "F1: 0.5033288948069241\n",
      "AUC:  0.9616530056340183\n"
     ]
    }
   ],
   "source": [
    "print('XGBClassifier')\n",
    "threshold = 0.2\n",
    "\n",
    "model_4 = XGBClassifier(use_label_encoder=False, n_estimators=100, num_parallel_tree=40)\n",
    "model_4.fit(X_filtered, y_train)\n",
    "y_pred = model_4.predict_proba(X_filtered)[:,1]\n",
    "predictions = np.where(y_pred>threshold,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          17054         2\n",
      "Real 1              1       253\n",
      "F1: 0.994106090373281\n",
      "AUC:  0.9999989612725473\n"
     ]
    }
   ],
   "source": [
    "print('RandomForestClassifier')\n",
    "threshold = 0.4\n",
    "\n",
    "model_2 = RandomForestClassifier(n_estimators=200, class_weight={0: 1, 1: 2},criterion = \"gini\")\n",
    "model_2.fit(X_test, y_test)\n",
    "y_pred = model_2.predict_proba(X_test)[:,1]\n",
    "predictions = np.where(y_pred>threshold,1,0)\n",
    "print_conf(confusion_matrix(y_test, predictions))\n",
    "print(\"F1:\",f1_score(y_test, predictions))\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, RandomForestClassifier gives us the best F1 score and the best true positive coefficient with an acceptable error rate. The data was prepared using tree methods. The model was well received with a large number of categorical values dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestClassifier(n_estimators=200, class_weight={0: 1, 1: 2},criterion = \"gini\")\n",
    "\n",
    "treshold = 0.4\n",
    "\n",
    "F1: 0.996\n",
    "\n",
    "AUC:  0.999"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
